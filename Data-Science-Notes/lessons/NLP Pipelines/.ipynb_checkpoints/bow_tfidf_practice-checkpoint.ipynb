{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words and TF-IDF\n",
    "Below, we'll look at three useful methods of vectorizing text.\n",
    "- `CountVectorizer` - Bag of Words\n",
    "- `TfidfTransformer` - TF-IDF values\n",
    "- `TfidfVectorizer` - Bag of Words AND TF-IDF values\n",
    "\n",
    "Let's first use an example from earlier and apply the text processing steps we saw in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BlickWinkel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BlickWinkel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BlickWinkel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"The first time you see The Second Renaissance it may look boring.\",\n",
    "        \"Look at it at least twice and definitely watch part 2.\",\n",
    "        \"It will change your view of the matrix.\",\n",
    "        \"Are the human people the ones who started the war?\",\n",
    "        \"Is AI a bad thing ?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the skills you learned so far to create a function `tokenize` that takes in a string of text and applies the following:\n",
    "- case normalization (convert to all lowercase)\n",
    "- punctuation removal\n",
    "- tokenization, lemmatization, and stop word removal using `nltk`\n",
    "\n",
    "Feel free to refer back to previous sections to complete these steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # lemmatize andremove stop words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `CountVectorizer` (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize count vectorizer object\n",
    "vect = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts of each token (word) in text data\n",
    "X = vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x25 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 26 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to numpy array to view\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 6,\n",
       " 'time': 20,\n",
       " 'see': 17,\n",
       " 'second': 16,\n",
       " 'renaissance': 15,\n",
       " 'may': 11,\n",
       " 'look': 9,\n",
       " 'boring': 3,\n",
       " 'least': 8,\n",
       " 'twice': 21,\n",
       " 'definitely': 5,\n",
       " 'watch': 24,\n",
       " 'part': 13,\n",
       " '2': 0,\n",
       " 'change': 4,\n",
       " 'view': 22,\n",
       " 'matrix': 10,\n",
       " 'human': 7,\n",
       " 'people': 14,\n",
       " 'one': 12,\n",
       " 'started': 18,\n",
       " 'war': 23,\n",
       " 'ai': 1,\n",
       " 'bad': 2,\n",
       " 'thing': 19}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view token vocabulary and counts\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TfidfTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msmooth_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msublinear_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Transform a count matrix to a normalized tf or tf-idf representation\n",
       "\n",
       "Tf means term-frequency while tf-idf means term-frequency times inverse\n",
       "document-frequency. This is a common term weighting scheme in information\n",
       "retrieval, that has also found good use in document classification.\n",
       "\n",
       "The goal of using tf-idf instead of the raw frequencies of occurrence of a\n",
       "token in a given document is to scale down the impact of tokens that occur\n",
       "very frequently in a given corpus and that are hence empirically less\n",
       "informative than features that occur in a small fraction of the training\n",
       "corpus.\n",
       "\n",
       "The formula that is used to compute the tf-idf for a term t of a document d\n",
       "in a document set is tf-idf(t, d) = tf(t, d) * idf(t), and the idf is\n",
       "computed as idf(t) = log [ n / df(t) ] + 1 (if ``smooth_idf=False``), where\n",
       "n is the total number of documents in the document set and df(t) is the\n",
       "document frequency of t; the document frequency is the number of documents\n",
       "in the document set that contain the term t. The effect of adding \"1\" to\n",
       "the idf in the equation above is that terms with zero idf, i.e., terms\n",
       "that occur in all documents in a training set, will not be entirely\n",
       "ignored.\n",
       "(Note that the idf formula above differs from the standard textbook\n",
       "notation that defines the idf as\n",
       "idf(t) = log [ n / (df(t) + 1) ]).\n",
       "\n",
       "If ``smooth_idf=True`` (the default), the constant \"1\" is added to the\n",
       "numerator and denominator of the idf as if an extra document was seen\n",
       "containing every term in the collection exactly once, which prevents\n",
       "zero divisions: idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1.\n",
       "\n",
       "Furthermore, the formulas used to compute tf and idf depend\n",
       "on parameter settings that correspond to the SMART notation used in IR\n",
       "as follows:\n",
       "\n",
       "Tf is \"n\" (natural) by default, \"l\" (logarithmic) when\n",
       "``sublinear_tf=True``.\n",
       "Idf is \"t\" when use_idf is given, \"n\" (none) otherwise.\n",
       "Normalization is \"c\" (cosine) when ``norm='l2'``, \"n\" (none)\n",
       "when ``norm=None``.\n",
       "\n",
       "Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "norm : {'l1', 'l2'}, default='l2'\n",
       "    Each output row will have unit norm, either:\n",
       "    * 'l2': Sum of squares of vector elements is 1. The cosine\n",
       "    similarity between two vectors is their dot product when l2 norm has\n",
       "    been applied.\n",
       "    * 'l1': Sum of absolute values of vector elements is 1.\n",
       "    See :func:`preprocessing.normalize`\n",
       "\n",
       "use_idf : bool, default=True\n",
       "    Enable inverse-document-frequency reweighting.\n",
       "\n",
       "smooth_idf : bool, default=True\n",
       "    Smooth idf weights by adding one to document frequencies, as if an\n",
       "    extra document was seen containing every term in the collection\n",
       "    exactly once. Prevents zero divisions.\n",
       "\n",
       "sublinear_tf : bool, default=False\n",
       "    Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "idf_ : array of shape (n_features)\n",
       "    The inverse document frequency (IDF) vector; only defined\n",
       "    if  ``use_idf`` is True.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.feature_extraction.text import TfidfTransformer\n",
       ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
       ">>> from sklearn.pipeline import Pipeline\n",
       ">>> import numpy as np\n",
       ">>> corpus = ['this is the first document',\n",
       "...           'this document is the second document',\n",
       "...           'and this is the third one',\n",
       "...           'is this the first document']\n",
       ">>> vocabulary = ['this', 'document', 'first', 'is', 'second', 'the',\n",
       "...               'and', 'one']\n",
       ">>> pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
       "...                  ('tfid', TfidfTransformer())]).fit(corpus)\n",
       ">>> pipe['count'].transform(corpus).toarray()\n",
       "array([[1, 1, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 2, 0, 1, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0]])\n",
       ">>> pipe['tfid'].idf_\n",
       "array([1.        , 1.22314355, 1.51082562, 1.        , 1.91629073,\n",
       "       1.        , 1.91629073, 1.91629073])\n",
       ">>> pipe.transform(corpus).shape\n",
       "(4, 8)\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       ".. [Yates2011] R. Baeza-Yates and B. Ribeiro-Neto (2011). Modern\n",
       "               Information Retrieval. Addison Wesley, pp. 68-74.\n",
       "\n",
       ".. [MRS2008] C.D. Manning, P. Raghavan and H. Schütze  (2008).\n",
       "               Introduction to Information Retrieval. Cambridge University\n",
       "               Press, pp. 118-120.\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\users\\blickwinkel\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TfidfTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# initialize tf-idf transformer object\n",
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use counts from count vectorizer results to compute tf-idf values\n",
    "tfidf = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.36419547, 0.        ,\n",
       "        0.        , 0.36419547, 0.        , 0.        , 0.26745392,\n",
       "        0.        , 0.36419547, 0.        , 0.        , 0.        ,\n",
       "        0.36419547, 0.36419547, 0.36419547, 0.        , 0.        ,\n",
       "        0.36419547, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.39105193, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.39105193, 0.        , 0.        , 0.39105193, 0.28717648,\n",
       "        0.        , 0.        , 0.        , 0.39105193, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.39105193, 0.        , 0.        , 0.39105193],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.57735027, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to numpy array to view\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TfidfVectorizer`\n",
    "`TfidfVectorizer` = `CountVectorizer` + `TfidfTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize tf-idf vectorizer object\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bag of word counts and tf-idf values\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30298183, 0.        , 0.        , 0.30298183, 0.        ,\n",
       "        0.        , 0.20291046, 0.        , 0.24444384, 0.        ,\n",
       "        0.30298183, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30298183, 0.30298183, 0.30298183, 0.        , 0.40582093,\n",
       "        0.        , 0.30298183, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30298183, 0.        ],\n",
       "       [0.        , 0.30015782, 0.        , 0.60031564, 0.        ,\n",
       "        0.        , 0.        , 0.30015782, 0.        , 0.        ,\n",
       "        0.        , 0.20101919, 0.30015782, 0.24216544, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30015782, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30015782, 0.        , 0.        ,\n",
       "        0.30015782, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.38077552, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25500981, 0.        , 0.        , 0.38077552,\n",
       "        0.        , 0.38077552, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25500981,\n",
       "        0.        , 0.        , 0.        , 0.38077552, 0.        ,\n",
       "        0.        , 0.        , 0.38077552, 0.        , 0.38077552],\n",
       "       [0.        , 0.        , 0.30101067, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30101067,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30101067, 0.        , 0.30101067,\n",
       "        0.        , 0.        , 0.        , 0.30101067, 0.60477106,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30101067,\n",
       "        0.        , 0.30101067, 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to numpy array to view\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.30298183, 0.        , 0.        , 0.30298183, 0.        ,\n",
       "       0.        , 0.20291046, 0.        , 0.24444384, 0.        ,\n",
       "       0.30298183, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.30298183, 0.30298183, 0.30298183, 0.        , 0.40582093,\n",
       "       0.        , 0.30298183, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30298183, 0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.30015782, 0.        , 0.60031564, 0.        ,\n",
       "       0.        , 0.        , 0.30015782, 0.        , 0.        ,\n",
       "       0.        , 0.20101919, 0.30015782, 0.24216544, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30015782, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.30015782, 0.        , 0.        ,\n",
       "       0.30015782, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
