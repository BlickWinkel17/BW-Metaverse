{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: LASSO (coordinate descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement your very own LASSO solver via coordinate descent. You will:\n",
    "* Write a function to normalize features\n",
    "* Implement coordinate descent for LASSO\n",
    "* Explore effects of L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Turi Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = turicreate.SFrame('home_data.sframe/')\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float and then to int, before using it below\n",
    "sales['floors'] = sales['floors'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do any \"feature engineering\" like creating new features or adjusting existing ones we should do this directly using the SFrames as seen in the first notebook of Week 2. For this notebook, however, we will work with the existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful functions from previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we convert the SFrame into a 2D Numpy array. Copy and paste `get_num_data()` from the second notebook of Week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, copy and paste the `predict_output()` function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize features\n",
    "In the house dataset, features vary wildly in their relative magnitude: `sqft_living` is very large overall compared to `bedrooms`, for instance. As a result, weight for `sqft_living` would be much smaller than weight for `bedrooms`. This is problematic because \"small\" weights are dropped first as `l1_penalty` goes up. \n",
    "\n",
    "To give equal considerations for all features, we need to **normalize features** as discussed in the lectures: we divide each feature by its 2-norm so that the transformed feature has norm 1.\n",
    "\n",
    "Let's see how we can do this normalization easily with Numpy: let us first consider a small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  5.  8.]\n",
      " [ 4. 12. 15.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[3.,5.,8.],[4.,12.,15.]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy provides a shorthand for computing 2-norms of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 13. 17.]\n"
     ]
    }
   ],
   "source": [
    "norms = np.linalg.norm(X, axis=0) # gives [norm(X[:,0]), norm(X[:,1]), norm(X[:,2])]\n",
    "print(norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize, apply element-wise division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6        0.38461538 0.47058824]\n",
      " [0.8        0.92307692 0.88235294]]\n"
     ]
    }
   ],
   "source": [
    "print(X / norms) # gives [X[:,0]/norm(X[:,0]), X[:,1]/norm(X[:,1]), X[:,2]/norm(X[:,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the shorthand we just covered, write a short function called `normalize_features(feature_matrix)`, which normalizes columns of a given feature matrix. The function should return a pair `(normalized_features, norms)`, where the second item contains the norms of original features. As discussed in the lectures, we will use these norms to normalize the test data in the same way as we normalized the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norm = np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features = feature_matrix/norm\n",
    "    return (normalized_features, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6 0.6 0.6]\n",
      " [0.8 0.8 0.8]]\n",
      "[ 5. 10. 15.]\n"
     ]
    }
   ],
   "source": [
    "features, norms = normalize_features(np.array([[3.,6.,9.],[4.,8.,12.]]))\n",
    "print(features)\n",
    "# should print\n",
    "# [[ 0.6  0.6  0.6]\n",
    "#  [ 0.8  0.8  0.8]]\n",
    "print(norms)\n",
    "# should print\n",
    "# [5.  10.  15.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Coordinate Descent with normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seek to obtain a sparse set of weights by minimizing the LASSO cost function\n",
    "```\n",
    "SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|).\n",
    "```\n",
    "(By convention, we do not include `w[0]` in the L1 penalty term. We never want to push the intercept to zero.)\n",
    "\n",
    "The absolute value sign makes the cost function non-differentiable, so simple gradient descent is not viable (you would need to implement a method called subgradient descent). Instead, we will use **coordinate descent**: at each iteration, we will fix all weights but weight `i` and find the value of weight `i` that minimizes the objective. That is, we look for\n",
    "```\n",
    "argmin_{w[i]} [ SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|) ]\n",
    "```\n",
    "where all weights other than `w[i]` are held to be constant. We will optimize one `w[i]` at a time, circling through the weights multiple times.  \n",
    "  1. Pick a coordinate `i`\n",
    "  2. Compute `w[i]` that minimizes the cost function `SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|)`\n",
    "  3. Repeat Steps 1 and 2 for all coordinates, multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we use **cyclical coordinate descent with normalized features**, where we cycle through coordinates 0 to (d-1) in order, and assume the features were normalized as discussed above. The formula for optimizing each coordinate is as follows:\n",
    "```\n",
    "       ┌ (ro[i] + lambda/2)     if ro[i] < -lambda/2\n",
    "w[i] = ├ 0                      if -lambda/2 <= ro[i] <= lambda/2\n",
    "       └ (ro[i] - lambda/2)     if ro[i] > lambda/2\n",
    "```\n",
    "where\n",
    "```\n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ].\n",
    "```\n",
    "\n",
    "Note that we do not regularize the weight of the constant feature (intercept) `w[0]`, so, for this weight, the update is simply:\n",
    "```\n",
    "w[0] = ro[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple model with 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to normalize features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_feature_matrix, norms = normalize_features(simple_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign some random set of initial weights and inspect the values of `ro[i]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([1., 4., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `predict_output()` to make predictions on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_output(simple_feature_matrix, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 3), (21613,), (21613,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_feature_matrix.shape, output.shape, prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221899.98736219, 537999.98736219, 179999.98930743, ...,\n",
       "       402100.98930743, 399999.98736219, 324999.98930743])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output - prediction + weights[1] * simple_feature_matrix[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the values of `ro[i]` for each feature in this simple model, using the formula given above, using the formula:\n",
    "```\n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]\n",
    "```\n",
    "\n",
    "*Hint: You can get a Numpy vector for feature_i using:*\n",
    "```\n",
    "simple_feature_matrix[:,i]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = []\n",
    "for i in range(len(weights)):\n",
    "    ro.append((simple_feature_matrix[:,i] * (output - prediction + weights[i] * simple_feature_matrix[:,i])).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.793947e+07 8.096670e+07\n"
     ]
    }
   ],
   "source": [
    "print('%e %e'%(ro[1],ro[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "Recall that, whenever `ro[i]` falls between `-l1_penalty/2` and `l1_penalty/2`, the corresponding weight `w[i]` is sent to zero. Now suppose we were to take one step of coordinate descent on either feature 1 or feature 2. What range of values of `l1_penalty` **would not** set `w[1]` zero, but **would** set `w[2]` to zero, if we were to take a step in that coordinate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ro[1] not in [-l1_penalty/2, l1_penalty/2]\n",
    "# ro[2] in [-l1_penalty/2, l1_penalty/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What range of values of `l1_penalty` would set **both** `w[1]` and `w[2]` to zero, if we were to take a step in that coordinate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ro[1] in [-l1_penalty/2, l1_penalty/2]\n",
    "# ro[2] in [-l1_penalty/2, l1_penalty/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can say that `ro[i]` quantifies the significance of the i-th feature: the larger `ro[i]` is, the more likely it is for the i-th feature to be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Coordinate Descent Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the formula above, implement coordinate descent that minimizes the cost function over a single feature i. Note that the intercept (weight 0) is not regularized. The function should accept feature matrix, output, current weights, l1 penalty, and index of feature to optimize over. The function should return new weight for feature i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    prediction = predict_output(feature_matrix, weights)\n",
    "    # compute ro[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    ro_i = (feature_matrix[:,i] * (output - prediction + weights[i] * feature_matrix[:,i])).sum()\n",
    "\n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = ro_i \n",
    "    elif ro_i < -l1_penalty/2.:\n",
    "        new_weight_i = ro_i + l1_penalty/2\n",
    "    elif ro_i > l1_penalty/2.:\n",
    "        new_weight_i = ro_i - l1_penalty/2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4255588466910251\n"
     ]
    }
   ],
   "source": [
    "# should print 0.425558846691\n",
    "import math\n",
    "print(lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],[2./math.sqrt(13),3./math.sqrt(10)]]), \n",
    "                                    np.array([1., 1.]), np.array([1., 4.]), 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical coordinate descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that optimizes the cost function over a single coordinate, let us implement cyclical coordinate descent where we optimize coordinates 0, 1, ..., (d-1) in order and repeat.\n",
    "\n",
    "When do we know to stop? Each time we scan all the coordinates (features) once, we measure the change in weight for each coordinate. If no coordinate changes by more than a specified threshold, we stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each iteration:\n",
    "1. As you loop over features in order and perform coordinate descent, measure how much each coordinate changes.\n",
    "2. After the loop, if the maximum change across all coordinates is falls below the tolerance, stop. Otherwise, go back to step 1.\n",
    "\n",
    "Return weights\n",
    "\n",
    "**IMPORTANT: when computing a new weight for coordinate i, make sure to incorporate the new weights for coordinates 0, 1, ..., i-1. One good way is to update your weights variable in-place. See following pseudocode for illustration.**\n",
    "```\n",
    "for i in range(len(weights)):\n",
    "    old_weights_i = weights[i] # remember old value of weight[i], as it will be overwritten\n",
    "    # the following line uses new values for weight[0], weight[1], ..., weight[i-1]\n",
    "    #     and old values for weight[i], ..., weight[d-1]\n",
    "    weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "    \n",
    "    # use old_weights_i to compute change in coordinate\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    \n",
    "    converge = False\n",
    "    print('The initial weights is %s'%initial_weights)\n",
    "    weights = np.array(initial_weights)\n",
    "    k = len(weights)\n",
    "    \n",
    "    while not converge:\n",
    "        change = 0 \n",
    "        for i in range(k):\n",
    "            old_weights_i = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            #print(\"weights[%s] updated to %s\"%(i,weights[i]))\n",
    "            change = max(abs(old_weights_i - weights[i]),change)\n",
    "        #print(\"Max change this loop is %s\"%change)\n",
    "        if change < tolerance:\n",
    "            converge = True\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following parameters, learn the weights on the sales dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a normalized version of the feature matrix, `normalized_simple_feature_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)\n",
    "(normalized_simple_feature_matrix, simple_norms) = normalize_features(simple_feature_matrix) # normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00680209, 0.00353021, 0.00583571],\n",
       "       [0.00680209, 0.00768869, 0.00583571],\n",
       "       [0.00680209, 0.00230361, 0.00389048],\n",
       "       ...,\n",
       "       [0.00680209, 0.00305154, 0.00389048],\n",
       "       [0.00680209, 0.00478673, 0.00583571],\n",
       "       [0.00680209, 0.00305154, 0.00389048]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_simple_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run your implementation of LASSO coordinate descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weights is [0. 0. 0.]\n",
      "weights[i] updated to  79400304.65805088\n",
      "weights[i] updated to  10305258.636021176\n",
      "weights[i] updated to  -299724.1144988239\n",
      "Max change this loop is 79400304.65805088\n",
      "weights[i] updated to  70262136.29155378\n",
      "weights[i] updated to  18947595.63474386\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 9138168.3664971\n",
      "weights[i] updated to  62067326.88218397\n",
      "weights[i] updated to  26161208.08576558\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 8194809.409369811\n",
      "weights[i] updated to  55468421.84391067\n",
      "weights[i] updated to  32197787.954702266\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 6598905.038273297\n",
      "weights[i] updated to  49946248.649615586\n",
      "weights[i] updated to  37249389.59832677\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 5522173.194295086\n",
      "weights[i] updated to  45325118.83930232\n",
      "weights[i] updated to  41476730.19845453\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 4621129.8103132695\n",
      "weights[i] updated to  41458010.73305394\n",
      "weights[i] updated to  45014302.99421173\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 3867108.1062483788\n",
      "weights[i] updated to  38221891.92244686\n",
      "weights[i] updated to  47974656.1970985\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 3236118.8106070757\n",
      "weights[i] updated to  35513804.982895374\n",
      "weights[i] updated to  50451973.72293222\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2708086.9395514876\n",
      "weights[i] updated to  33247591.873496704\n",
      "weights[i] updated to  52525071.66199516\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2266213.1093986705\n",
      "weights[i] updated to  31351152.81084942\n",
      "weights[i] updated to  54259905.820365965\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1896439.062647283\n",
      "weights[i] updated to  29764152.407657497\n",
      "weights[i] updated to  55711670.11009872\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1587000.403191924\n",
      "weights[i] updated to  28436100.096703943\n",
      "weights[i] updated to  56926552.548730515\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1328052.3109535538\n",
      "weights[i] updated to  27324743.76870193\n",
      "weights[i] updated to  57943204.735407196\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1111356.3280020133\n",
      "weights[i] updated to  26394725.51746054\n",
      "weights[i] updated to  58793971.55514863\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 930018.2512413897\n",
      "weights[i] updated to  25616456.72477092\n",
      "weights[i] updated to  59505920.234410286\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 778268.7926896214\n",
      "weights[i] updated to  24965176.69573272\n",
      "weights[i] updated to  60101701.487440914\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 651280.0290381983\n",
      "weights[i] updated to  24420164.89491498\n",
      "weights[i] updated to  60600270.15088847\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 545011.8008177392\n",
      "weights[i] updated to  23964081.720570996\n",
      "weights[i] updated to  61017488.23371242\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 456083.1743439846\n",
      "weights[i] updated to  23582416.843576435\n",
      "weights[i] updated to  61366629.56849186\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 381664.8769945614\n",
      "weights[i] updated to  23263027.55994238\n",
      "weights[i] updated to  61658802.119658604\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 319389.2836340554\n",
      "weights[i] updated to  22995752.46954488\n",
      "weights[i] updated to  61903301.384431176\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 267275.0903974995\n",
      "weights[i] updated to  22772088.190223448\n",
      "weights[i] updated to  62107906.12993382\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 223664.2793214321\n",
      "weights[i] updated to  22584918.821877252\n",
      "weights[i] updated to  62279125.875404775\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 187169.36834619567\n",
      "weights[i] updated to  22428289.553433515\n",
      "weights[i] updated to  62422407.993163705\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 156629.26844373718\n",
      "weights[i] updated to  22297217.20997265\n",
      "weights[i] updated to  62542311.01727468\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 131072.34346086532\n",
      "weights[i] updated to  22187531.712549232\n",
      "weights[i] updated to  62642649.67373666\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 109685.49742341787\n",
      "weights[i] updated to  22095743.406737655\n",
      "weights[i] updated to  62726616.246350184\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 91788.30581157655\n",
      "weights[i] updated to  22018932.038948216\n",
      "weights[i] updated to  62796882.13952699\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 76811.36778943986\n",
      "weights[i] updated to  21954653.848284185\n",
      "weights[i] updated to  62855682.86927286\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 64278.19066403061\n",
      "weights[i] updated to  21900863.818058874\n",
      "weights[i] updated to  62904889.18633975\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 53790.030225310475\n",
      "weights[i] updated to  21855850.613397233\n",
      "weights[i] updated to  62946066.594337106\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 45013.20466164127\n",
      "weights[i] updated to  21818182.134955715\n",
      "weights[i] updated to  62980525.156376526\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 37668.4784415178\n",
      "weights[i] updated to  21786659.956546843\n",
      "weights[i] updated to  63009361.17485298\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 31522.178408872336\n",
      "weights[i] updated to  21760281.197097257\n",
      "weights[i] updated to  63033492.07040873\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 26378.759449586272\n",
      "weights[i] updated to  21738206.613891955\n",
      "weights[i] updated to  63053685.5697574\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 22074.583205301315\n",
      "weights[i] updated to  21719733.901988305\n",
      "weights[i] updated to  63070584.130981654\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 18472.711903650314\n",
      "weights[i] updated to  21704275.350318193\n",
      "weights[i] updated to  63084725.383397534\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 15458.551670111716\n",
      "weights[i] updated to  21691339.143605087\n",
      "weights[i] updated to  63096559.232281834\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 12936.206713106483\n",
      "weights[i] updated to  21680513.71521467\n",
      "weights[i] updated to  63106462.172650754\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 10825.428390417248\n",
      "weights[i] updated to  21671454.65312367\n",
      "weights[i] updated to  63114749.26748434\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 9059.062091000378\n",
      "weights[i] updated to  21663873.742418908\n",
      "weights[i] updated to  63121684.1714848\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 7580.910704761744\n",
      "weights[i] updated to  21657529.79571269\n",
      "weights[i] updated to  63127487.519275725\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 6343.946706216782\n",
      "weights[i] updated to  21652220.97974338\n",
      "weights[i] updated to  63132343.94491336\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 5308.815969310701\n",
      "weights[i] updated to  21647778.39403119\n",
      "weights[i] updated to  63136407.95603654\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 4442.5857121907175\n",
      "weights[i] updated to  21644060.69729347\n",
      "weights[i] updated to  63139808.849541664\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 3717.696737717837\n",
      "weights[i] updated to  21640949.610658586\n",
      "weights[i] updated to  63142654.82517576\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 3111.0866348855197\n",
      "weights[i] updated to  21638346.15461237\n",
      "weights[i] updated to  63145036.42792153\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2603.45604621619\n",
      "weights[i] updated to  21636167.499955647\n",
      "weights[i] updated to  63147029.42869453\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2178.6546567231417\n",
      "weights[i] updated to  21634344.33258541\n",
      "weights[i] updated to  63148697.23500195\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1823.16737023741\n",
      "weights[i] updated to  21632818.64826017\n",
      "weights[i] updated to  63150092.90825844\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1525.6843252405524\n",
      "weights[i] updated to  21631541.90718951\n",
      "weights[i] updated to  63151260.85194005\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1276.7410706579685\n",
      "weights[i] updated to  21630473.489736073\n",
      "weights[i] updated to  63152238.22428495\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1068.4174534380436\n",
      "weights[i] updated to  21629579.40409801\n",
      "weights[i] updated to  63153056.12048629\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 894.0856380611658\n",
      "weights[i] updated to  21628831.204856582\n",
      "weights[i] updated to  63153740.561988726\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 748.1992414295673\n",
      "weights[i] updated to  21628205.087982476\n",
      "weights[i] updated to  63154313.32436308\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 626.1168741062284\n",
      "weights[i] updated to  21627681.133508414\n",
      "weights[i] updated to  63154792.63009821\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 523.9544740617275\n",
      "weights[i] updated to  21627242.671773486\n",
      "weights[i] updated to  63155193.728351176\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 438.4617349281907\n",
      "weights[i] updated to  21626875.753076322\n",
      "weights[i] updated to  63155529.38010065\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 366.91869716346264\n",
      "weights[i] updated to  21626568.703864045\n",
      "weights[i] updated to  63155810.26413867\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 307.0492122769356\n",
      "weights[i] updated to  21626311.755337052\n",
      "weights[i] updated to  63156045.31681731\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 256.9485269933939\n",
      "weights[i] updated to  21626096.73265377\n",
      "weights[i] updated to  63156242.0163597\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 215.02268328145146\n",
      "weights[i] updated to  21625916.794847284\n",
      "weights[i] updated to  63156406.62078029\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 179.93780648708344\n",
      "weights[i] updated to  21625766.217179336\n",
      "weights[i] updated to  63156544.3669842\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 150.57766794785857\n",
      "weights[i] updated to  21625640.209007263\n",
      "weights[i] updated to  63156659.6373799\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 126.00817207247019\n",
      "weights[i] updated to  21625534.761369187\n",
      "weights[i] updated to  63156756.09930585\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 105.44763807579875\n",
      "weights[i] updated to  21625446.519438602\n",
      "weights[i] updated to  63156836.82170732\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 88.24193058535457\n",
      "weights[i] updated to  21625372.67579017\n",
      "weights[i] updated to  63156904.37277511\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 73.8436484336853\n",
      "weights[i] updated to  21625310.88108127\n",
      "weights[i] updated to  63156960.9016528\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 61.79470890015364\n",
      "weights[i] updated to  21625259.169307403\n",
      "weights[i] updated to  63157008.20681195\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 51.71177386492491\n",
      "weights[i] updated to  21625215.895253636\n",
      "weights[i] updated to  63157047.79327066\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 43.274053767323494\n",
      "weights[i] updated to  21625179.682151865\n",
      "weights[i] updated to  63157080.92047584\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 36.21310177072883\n",
      "weights[i] updated to  21625149.37787885\n",
      "weights[i] updated to  63157108.64237264\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 30.304273016750813\n",
      "weights[i] updated to  21625124.018301286\n",
      "weights[i] updated to  63157131.84093581\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 25.35957756265998\n",
      "weights[i] updated to  21625102.796601832\n",
      "weights[i] updated to  63157151.25422983\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 21.221699453890324\n",
      "weights[i] updated to  21625085.03761013\n",
      "weights[i] updated to  63157167.49989046\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 17.758991703391075\n",
      "weights[i] updated to  21625070.176322177\n",
      "weights[i] updated to  63157181.09477493\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 14.861287951469421\n",
      "weights[i] updated to  21625057.739924707\n",
      "weights[i] updated to  63157192.47140579\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 12.436397470533848\n",
      "weights[i] updated to  21625047.332752544\n",
      "weights[i] updated to  63157201.9917316\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 10.407172162085772\n",
      "weights[i] updated to  21625038.623700544\n",
      "weights[i] updated to  63157209.95864242\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 8.709052000194788\n",
      "weights[i] updated to  21625031.335689396\n",
      "weights[i] updated to  63157216.62560627\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 7.288011148571968\n",
      "weights[i] updated to  21625025.236850344\n",
      "weights[i] updated to  63157222.20473325\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 6.0988390520215034\n",
      "weights[i] updated to  21625020.133148223\n",
      "weights[i] updated to  63157226.87352379\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 5.103702120482922\n",
      "weights[i] updated to  21625015.862208303\n",
      "weights[i] updated to  63157230.78051591\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 4.2709399200975895\n",
      "weights[i] updated to  21625012.288150206\n",
      "weights[i] updated to  63157234.05001092\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 3.574058096855879\n",
      "weights[i] updated to  21625009.297264952\n",
      "weights[i] updated to  63157236.78602813\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2.990885253995657\n",
      "weights[i] updated to  21625006.79439723\n",
      "weights[i] updated to  63157239.075614184\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2.5028677210211754\n",
      "weights[i] updated to  21625004.699918073\n",
      "weights[i] updated to  63157240.991612464\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 2.0944791585206985\n",
      "weights[i] updated to  21625002.947191432\n",
      "weights[i] updated to  63157242.59498064\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1.7527266405522823\n",
      "weights[i] updated to  21625001.480454147\n",
      "weights[i] updated to  63157243.93673003\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1.4667372852563858\n",
      "weights[i] updated to  21625000.25304183\n",
      "weights[i] updated to  63157245.0595485\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1.2274123169481754\n",
      "weights[i] updated to  21624999.22590425\n",
      "weights[i] updated to  63157245.99915862\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 1.0271375812590122\n",
      "weights[i] updated to  21624998.366362922\n",
      "weights[i] updated to  63157246.78545421\n",
      "weights[i] updated to  0.0\n",
      "Max change this loop is 0.8595413267612457\n",
      "[21624998.36636292 63157246.78545421        0.        ]\n"
     ]
    }
   ],
   "source": [
    "simple_weights = lasso_cyclical_coordinate_descent(normalized_simple_feature_matrix, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print(simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_output(normalized_simple_feature_matrix, simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.630492e+15\n"
     ]
    }
   ],
   "source": [
    "error = prediction - output\n",
    "RSS = (error*error).sum()\n",
    "print('%e'%RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What is the RSS of the learned model on the normalized dataset? (Hint: use the normalized feature matrix when you make predictions.)\n",
    "2. Which features had weight zero at convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LASSO fit with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the sales dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']\n",
    "my_output = 'price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a normalized feature matrix from the TRAINING data with these features.  (Make you store the norms for the normalization, since we'll use them later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_feature_matrix, train_output) = get_numpy_data(train_data, all_features, my_output)\n",
    "(normalized_train_feature_matrix, train_norms) = normalize_features(train_feature_matrix) # normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, learn the weights with `l1_penalty=1e7`, on the training data. Initialize weights to all zeros, and set the `tolerance=1`.  Call resulting weights `weights1e7`, you will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(len(all_features)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weights is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[24429600.60933314        0.                0.         48389174.35227978\n",
      "        0.                0.          3317511.16271981  7329961.9848964\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.        ]\n"
     ]
    }
   ],
   "source": [
    "l1_penalty = 1e7\n",
    "tolerance = 1.0\n",
    "weights1e7 = lasso_cyclical_coordinate_descent(normalized_train_feature_matrix, train_output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print(weights1e7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, learn the weights with `l1_penalty=1e8`, on the training data. Initialize weights to all zeros, and set the `tolerance=1`.  Call resulting weights `weights1e8`, you will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weights is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[71114625.75280938        0.                0.                0.\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.        ]\n"
     ]
    }
   ],
   "source": [
    "l1_penalty = 1e8\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalized_train_feature_matrix, train_output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print(weights1e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, learn the weights with `l1_penalty=1e4`, on the training data. Initialize weights to all zeros, and set the `tolerance=5e5`.  Call resulting weights `weights1e4`, you will need them later.  (This case will take quite a bit longer to converge than the others above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weights is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 77779073.91265222 -22884012.25023364  15348487.08089997\n",
      "  92166869.69883077  -2139328.08242779  -8818455.54409495\n",
      "   6494209.73310655   7065162.05053197   4119079.21006763\n",
      "  18436483.52618777 -14566678.54514343  -5528348.75179427\n",
      " -83591746.2073053    2784276.46012858]\n"
     ]
    }
   ],
   "source": [
    "l1_penalty = 1e4\n",
    "tolerance = 5e5\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_train_feature_matrix, train_output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "print(weights1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we normalized our feature matrix, before learning the weights.  To use these weights on a test set, we must normalize the test data in the same way.\n",
    "\n",
    "Alternatively, we can rescale the learned weights to include the normalization, so we never have to worry about normalizing the test data: \n",
    "\n",
    "In this case, we must scale the resulting weights so that we can make predictions with *original* features:\n",
    " 1. Store the norms of the original features to a vector called `norms`:\n",
    "```\n",
    "features, norms = normalize_features(features)\n",
    "```\n",
    " 2. Run Lasso on the normalized features and obtain a `weights` vector\n",
    " 3. Compute the weights for the original features by performing element-wise division, i.e.\n",
    "```\n",
    "weights_normalized = weights / norms\n",
    "```\n",
    "Now, we can apply `weights_normalized` to the test data, without normalizing it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized version of each of the weights learned above. (`weights1e4`, `weights1e7`, `weights1e8`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00758447, 0.00652117, 0.0033687 , ..., 0.        , 0.00752148,\n",
       "         0.        ],\n",
       "        [0.00758447, 0.00652117, 0.00757957, ..., 0.0057043 , 0.0075061 ,\n",
       "         0.03707954],\n",
       "        [0.00758447, 0.00434745, 0.0033687 , ..., 0.        , 0.00743684,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.00758447, 0.00652117, 0.00842175, ..., 0.        , 0.00772924,\n",
       "         0.        ],\n",
       "        [0.00758447, 0.00652117, 0.00842175, ..., 0.        , 0.00771   ,\n",
       "         0.        ],\n",
       "        [0.00758447, 0.00434745, 0.00252652, ..., 0.        , 0.00772539,\n",
       "         0.        ]]),\n",
       " array([1.31848398e+02, 4.60040216e+02, 2.96850552e+02, 2.99962419e+05,\n",
       "        5.81709718e+06, 2.04107815e+02, 1.15325626e+01, 1.05933942e+02,\n",
       "        4.57793622e+02, 1.02101959e+03, 2.59726472e+05, 7.01224951e+04,\n",
       "        2.59922094e+05, 5.36953839e+04]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_feature_matrix, train_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_weights1e7 = weights1e7/train_norms\n",
    "normalized_weights1e8 = weights1e8/train_norms\n",
    "normalized_weights1e4 = weights1e4/train_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.3174562483786"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_weights1e7[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your results, if you call `normalized_weights1e7` the normalized version of `weights1e7`, then:\n",
    "```\n",
    "print normalized_weights1e7[3]\n",
    "```\n",
    "should return 161.31745624837794."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating each of the learned models on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the three models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, all_features, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS of each of the three normalized weights on the (unnormalized) `test_feature_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415969.49505193415\n",
      "RSS1e7: 2.759621e+14\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_feature_matrix, normalized_weights1e7)\n",
    "error1e7 = prediction - test_output\n",
    "RSS1e7 = (error1e7*error1e7).sum()\n",
    "print(prediction[0])\n",
    "print('RSS1e7: %e'%RSS1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539366.628221353\n",
      "RSS1e8: 5.371662e+14\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_feature_matrix, normalized_weights1e8)\n",
    "error1e8 = prediction - test_output\n",
    "RSS1e8 = (error1e8*error1e8).sum()\n",
    "print(prediction[0])\n",
    "print('RSS1e8: %e'%RSS1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343705.8378415003\n",
      "RSS1e4: 2.277810e+14\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_feature_matrix, normalized_weights1e4)\n",
    "error1e4 = prediction - test_output\n",
    "RSS1e4 = (error1e4*error1e4).sum()\n",
    "print(prediction[0])\n",
    "print('RSS1e4: %e'%RSS1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275962079909185.28,\n",
       " array([5.26090501e+10, 1.22397430e+10, 9.38605109e+10, ...,\n",
       "        5.08631015e+09, 1.94230571e+10, 1.88418527e+10]),\n",
       " array([1.13608350e+09, 7.83097230e+10, 5.05213491e+10, ...,\n",
       "        1.89028474e+07, 1.83901939e+10, 3.85383274e+10]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error1e7*error1e7).sum(), error1e8*error1e8, error1e4*error1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "Which model performed best on the test data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
